{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 13:  K-Nearest Neighbors Regression\n",
    "\n",
    "The *k-nearest neighbors* algorithm makes its predictions using the values of the k closest training data points.  For example, the 3-nearest neighbor algorithm will find the 3 closest data points (using the Euclidean distance) in the training data and use them to make a prediction.\n",
    "\n",
    "If we are performing regression (trying to predict a quantitative value), the prediction is the mean of the y values of the k neighbors.\n",
    "\n",
    "For this lab, we will use the building sale price data from Homework 9, which contains information about building sales in New York City from September 2016 to September 2017.  We will used the somewhat cleaned [version from Kaggle](https://www.kaggle.com/new-york-city/nyc-property-sales), which was originally taken from [New York City's Department of Finance Rolling Sales dataset](https://www1.nyc.gov/site/finance/taxes/property-rolling-sales-data.page).\n",
    "\n",
    "Data URL:  [https://raw.githubusercontent.com/megan-owen/MAT328-Techniques_in_Data_Science/main/data/nyc-rolling-sales.csv](https://raw.githubusercontent.com/megan-owen/MAT328-Techniques_in_Data_Science/main/data/nyc-rolling-sales.csv)\n",
    "\n",
    "### Section 1: Loading and cleaning the data\n",
    "\n",
    "First import the libraries we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data into the DataFrame `nyc`.  Missing values are stored as \" -  \" (a space, a a dash, and then two spaces) in the CSV file, so include the parameter to have Pandas convert them to Nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Hint:</summary>\n",
    "    Use the parameter `na_values = [\" - \"]` to have Pandas store the missing data as Nan.\n",
    "    </details>\n",
    "    \n",
    "Display your DataFrame if you haven't already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will try to predict the sales price from other information about the building.  Look at the columns - which do you think would not be helpful in determining the sales price or can not be easily used as/converted into quantitative data?  We will drop such columns.\n",
    "\n",
    "Qualitative columns will need to be made into dummy variables, which could add a lot of new columns (ex. for the neighborhood column) and slow down computation speed.  So we are also balancing how many new columns will be added with how useful we think that information will be.  \n",
    "\n",
    "Drop the following columns:\n",
    "* \"Unnamed: 0\" (some kind of left-over index column?)\n",
    "* \"EASE-MENT\" (seems empty for a lot of rows)\n",
    "* \"ADDRESS\"  (could be helpful for determining the sales price, but we would have to do something further with it, such as extracting the street name)\n",
    "* \"APARTMENT NUMBER\"  (empty for a lot of rows)\n",
    "* \"BLOCK\" (could be helpful, but likely there are very few repeated values)\n",
    "* \"LOT\" (lot numbers will be the same in different blocks, but that doesn't tell us anything about the property value)\n",
    "* \"TAX CLASS AT PRESENT\" (we will keep the \"TAX CLASS AT TIME OF SALE\" instead, but an argument could be made to keep \"TAX CLASS AT PRESENT\" instead)\n",
    "* \"BUILDING CLASS AT PRESENT\"  (we will keep the \"TAX CLASS AT TIME OF SALE\" instead, but an argument could be made to keep \"BUILDING CLASS AT PRESENT\" instead)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Hint:</summary>\n",
    "Pattern for dropping multiple columns:\n",
    "    <code>df.drop(columns = [\"col1\", \"col2\", \"col3\"], inplace = True)</code>\n",
    "</details>\n",
    "\n",
    "Next let's drop any rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the length of the new DataFrame to make sure we still have enough data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because both the sale price and gross square feet column have outliers (feel free to plot each as a histogram to verify), we will filter the data as in Homework 9 to remove these outliers.\n",
    "\n",
    "First filter the DataFrame to only include sale prices between 20,000 and 2,000,000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next filter the DataFrame to only include gross square feet greater than 0 or less than 6000 sq. ft.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sale date might affect the sale price, but right now the `SALE DATE` column is not in a format that can be used to make predictions.  To change it to a usable format, we should:\n",
    "* change the type of the column to a DateTime object\n",
    "* create a new column containing only the month\n",
    "* create a new column containing only the yera\n",
    "* drop the `SALE DATE` column (as a DateTime type), since it still can't be used by scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, make most of the qualitative columns into dummy variables.  We will treat `MONTH` as a quantitative variable, under the assumption that sales in consecutive months are similar (though this will not cover the December-January).\n",
    "\n",
    "Specifically, make the following columns into dummy variables: `\"BOROUGH\",\"NEIGHBORHOOD\",\"BUILDING CLASS CATEGORY\", \"ZIP CODE\", \"TAX CLASS AT TIME OF SALE\", \"BUILDING CLASS AT TIME OF SALE\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many columns does our new dataset have? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " It is ok that it is so large!  Part of what makes data science so powerful is that modern computers can quickly do computations even when we have a lot of variables.\n",
    "\n",
    "### Section 2: K-Nearest Neighbors\n",
    "\n",
    "First create a new DataFrame `x` with only the independent variables (every column except `SALE PRICE`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also create a new Series `y` with only the dependent variable (`SALE PRICE`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the `x` and `y` data into a training and testing set using `train_test_split()`.  Use a proportion of 0.2 of the data for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates a 7-nearest neighbor regressor object and fits it to our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors = 7)\n",
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use it to make predictions from our test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean squared error of the test predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Answer:</summary>\n",
    "<code>mean_squared_error(y_test_pred, y_test)</code>\n",
    "</details>\n",
    "\n",
    "We'll compare this mean squared error (MSE) to the MSE of the training data to check for overfitting.\n",
    "\n",
    "First predict `y` from the training data, and then compute its mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the two mean squared error compare?  Do you think the model overfits the data?\n",
    "\n",
    "Just as with linear regression, we can look for systematic error (error that has a pattern) by plotting the true `y` values of the test data on the x-axis against the error (true `y` values - predicted `y` values) on the y-axis.  Can you figure out the code to do this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Answer:</summary>\n",
    "<code>plt.scatter(y_test, y_test - y_test_pred, alpha = 0.5)</code>\n",
    "</details>\n",
    "\n",
    "Which prices are being under-estimated (the error is positive) by our model?  Which prices are being over-estimated (the error is negative) by our model?\n",
    "\n",
    "### Section 3: Scaling\n",
    "\n",
    "Notice that the values in some columns, like `LAND SQUARE FEET` and `GROSS SQUARE FEET`, are large, while the values in all the dummy variables columns are small (0 or 1).\n",
    "\n",
    "When the columns have different scales, the largest column(s) will dominate.  We can get better results by scaling all of our columns to be between 0 and 1.  The scaling formula is:\n",
    "\n",
    "$$x_{scaled} = \\frac{x - x_{\\min}}{x_{\\max} - x_{\\min}}$$\n",
    "\n",
    "We can use a built in function in sci-kit learn to do the scaling.  First we make a scaler object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we scale the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_scaled = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the scaled data look like?  Is this what you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale your x test data.  We do not need to scale the y data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and fit a 7-nearest neighbor regressor with the scaled training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this new model to make predictions from the scaled test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean squared error for these predictions.  Does scaling improve the 3-7earest neighbor regressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4:  Parameter search\n",
    "\n",
    "In k-nearest neighbors, k is called a *parameter* (similar to the parameters we pass into our code functions).  We can try to figure out the best k to use by trial and error, but it might be easier to systematically try all values of k in some range.\n",
    "\n",
    "Thus, we will write a loop to try all values of k between 1 and 20, and compute the mean squared error for each one.  The pseudo-code to do this is:\n",
    "\n",
    "<code>\n",
    "create an empty list\n",
    "loop k from 1 to 20:\n",
    "    create a k-nearest neighbor regressor\n",
    "    fit the training data to the k-nearest neighbor regressor\n",
    "    make predictions for the test data\n",
    "    compute the mean squared error for the predictions\n",
    "    store the mean squared error in the list\n",
    "</code>\n",
    "\n",
    "The code will take some time to run.  It will take longer to run for large k, so you can reduce the time by searching a smaller range of possible k's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mses = []\n",
    "for k in range(1,21):\n",
    "    print(\"Now computing MSE for k=\",k)\n",
    "    iknn_scaled = KNeighborsRegressor(n_neighbors = k)\n",
    "    iknn_scaled.fit(x_train_scaled, y_train)\n",
    "    iy_pred_scaled = iknn_scaled.predict(x_test_scaled)\n",
    "    mse = mean_squared_error(iy_pred_scaled, y_test)\n",
    "    mses.append(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot these mean squared errors as a line plot, to understand how increasing k changes the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(mses)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE for different numbers of neighbors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the mean squared errors change?  What k would you choose?  What other information would help you make this choice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
