{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 22 - Determining the number of clusters\n",
    "\n",
    "We will look at two methods for determining the number of clusters, using the penguin dataset from Labs 3 and 21.\n",
    "\n",
    "### Section 1: Loading, cleaning, and scaling the data\n",
    "\n",
    "This section is a subset of Sections 1 and 4 of Lab 21.\n",
    "\n",
    "We will use the Palmer penguin data set, which contains information about three species of penguins found in the Palmer Archipelago in Antarctica.\n",
    "\n",
    "The CSV file can be downloaded from https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv or it can be accessed directly through the Seaborn library using the following command. This second option only works for new versions of Seaborn, and may not work if using Jupyter Hub on Lehman 360 (in which case use the link for the CSV file above)\n",
    "\n",
    "Load the penguin data set into the variable penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For future reference, plot scatterplots of all pairs of quantitative variables, colored by the species of penguin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember in Lab 21 we got better results by scaling the quantitative columns to all have values between 0 and 1.  We will do that again here.\n",
    "\n",
    "First, create a new DataFrame `x` with only the quantitative columns in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a MinMaxScaler object (variable), and use it to scale the columns of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Inertia and the elbow method\n",
    "\n",
    "The first method, called the *elbow method*, asumes you have centers for the clusters, as in k-means clustering. It computes the sum of the squared distances of samples to their closest cluster center.\n",
    "\n",
    "Run the K-Means clustering algorithm with k = 3 clusters on the scaled data from Section 1, and store the assigned clusters in a variable called `clusters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Answer:</summary>\n",
    "<code>\n",
    "kmeans = KMeans(n_clusters = 4)\n",
    "kmeans.fit(x_scaled)\n",
    "clusters = kmeans.predict(x_scaled)\n",
    "clusters\n",
    "</code>\n",
    "</details>\n",
    "\n",
    "We can compute the sum of the squared distance of the samples to their closest cluster center as follows (`kmeans` should be the variable holding information about the k-means clustering algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the best k value, we make a loop to compute the inertia for each k, storing the result in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inertia_list = []\n",
    "for k in range(1,11):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(x_scaled)\n",
    "    clusters = kmeans.predict(x_scaled)\n",
    "    inertia_list.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the values in inertia_list.  You can use `range(1,11)` as the x values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1,11), inertia_list)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Inertia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Answer:</summary>\n",
    "<code>\n",
    "plt.plot(range(1,11), inertia_list)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "</code>\n",
    "</details>\n",
    "\n",
    "The elbow method tells us to look for where the curve straightens into a line, and that point is the suggested number of clusters.  We choose this point to avoid underfitting (ex. a larger k will give us a significantly smaller inertia) and overfitting (ex. the more clusters there are, the less variation in each cluster and the smaller the inertia but these different clusters might not be meaningful).\n",
    "\n",
    "In this example, someone could probably make the case for the elbow being at k = 2, k = 3, or k =5. In the next section, we will look at another method for determining the number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Silhouette score\n",
    "\n",
    "Instead of computing the inertia, which requires a cluster center, we can compute the silhouette score.  \n",
    "\n",
    "First the Silhouette Coefficient is calculated for each data point.  If a is the mean distance from that point to all other points in its cluster and if b is the mean distance to all other points in the nearest cluster that the point is not part of, then the Silhouette Coefficient for a data point is \n",
    "$$\\frac{b - a}{\\max\\{a,b\\}}$$\n",
    "\n",
    "The Silhouette Score is the mean silhouette coefficient for all data points.\n",
    "\n",
    "Let's compute the silhouette score for the penguin data with k = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "silhouette_score(x_scaled,clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should choose the k with the largest silhouette score.  We can again perform clustering for different k's using a loop, and compute the silhouette score for each.  Can you figure out how to modify the loop above to work for the silhouette scores?  You will need to start the loop at k=2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Answer:</summary>\n",
    "<code>\n",
    "silhouette_list = []\n",
    "for k in range(2,11):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(x_scaled)\n",
    "    clusters = kmeans.predict(x_scaled)\n",
    "    score = silhouette_score(x_scaled,clusters)\n",
    "    silhouette_list.append(score)\n",
    "</code>\n",
    "</details>\n",
    "\n",
    "Plot the silhouette scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Answer:</summary>\n",
    "<code>\n",
    "plt.plot(range(2,11), silhouette_list)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "</code>\n",
    "</details>\n",
    "\n",
    "This plot suggests k = 2 is the ideal number of clusters. Remember k = 2 was also where the sharpest bend was in the elbow method plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4: Clustering the penguin data with k = 2\n",
    "\n",
    "Let's cluster the penguin data with k = 2 to see why this is suggested (even though we know the correct answer is k = 3).  First perform the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, add the clusters to the penguin DataFrame in a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, plot the scatterplots for all pairs of quantitative columns, colored by the 2 clusters we just found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the scatter plots, why do you think the elbow methods suggest k = 2 as the ideal number of clusters?\n",
    "\n",
    "### Section 5: Simulated data\n",
    "\n",
    "Let's use some simulated data to better understand why and when the elbow method and silhouette score work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of clusters to make\n",
    "true_k = 4\n",
    "\n",
    "# Create true_k clusters, made up of 100 data points total.\n",
    "# x_blobs holds the 2 dimensional coordinates of each simulated data point and\n",
    "# y_blobs holds the true cluster number of that data point\n",
    "x_blobs, y_blobs = make_blobs(n_samples = 100, centers = true_k)\n",
    "\n",
    "# Create a DataFrame of the points and which cluster they belong to.\n",
    "df = pd.DataFrame(x_blobs, columns = [\"x_coord\", \"y_coord\"])\n",
    "df[\"cluster\"] = y_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a scatterplot of the simulated data points, colored by their cluster.  You can read the code above or display the DataFrame `df` to see the column names.  (You can also add this code in the cell above to make it easier to re-run the simulation and plot.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each simulated cluster is a different color.  If the points were all the same color, how many clusters would you think there are?\n",
    "\n",
    "Re-run the code several times.  What kind of variation is there?\n",
    "\n",
    "Use a loop to run the k-means clustering algorithm for k from 1 to 10.  Compute the inertia for each clustering and store them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Answer:</summary>\n",
    "<code>\n",
    "inertias = []\n",
    "for k in range(1,11):\n",
    "    kmeans_blobs = KMeans(n_clusters = k)\n",
    "    kmeans_blobs.fit(x_blobs)\n",
    "    inertias.append(kmeans_blobs.inertia_)\n",
    "</code>\n",
    "</details>\n",
    "\n",
    "Plot a line plot of the inertias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Answer:</summary>\n",
    "<code>\n",
    "plt.plot(range(1,11), inertias)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "</code>\n",
    "</details>\n",
    "\n",
    "Which k is the elbow at?  Does this match the number of simulated clusters?  Why or why not?  \n",
    "\n",
    "Try re-running the simulation code, loop, and plot several times.  Does the elbow always appear at the true k?  Why or why not?\n",
    "\n",
    "Next, write a loop to run the k-means clustering algorithm for k from 2 to 10. Compute the silhouette score for each clustering and store them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Answer:</summary>\n",
    "<code>\n",
    "scores = []\n",
    "for k in range(2,11):\n",
    "    kmeans_blobs = KMeans(n_clusters = k)\n",
    "    kmeans_blobs.fit(x_blobs)\n",
    "    cluster_blobs = kmeans_blobs.predict(x_blobs)\n",
    "    score = silhouette_score(x_blobs,cluster_blobs)\n",
    "    scores.append(score)\n",
    "</code>\n",
    "</details>\n",
    "\n",
    "Plot a line plot of the silhouette scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Answer:</summary>\n",
    "<code>\n",
    "plt.plot(range(2,11), scores)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Silhouette score\")\n",
    "</code>\n",
    "</details>\n",
    "\n",
    "Which k is the largest?  Does this match the number of simulated clusters?  Why or why not?  \n",
    "\n",
    "Try re-running the simulation code, loop, and plot several times.  Does the elbow always appear at the true k?  Why or why not?  How does it compare to the k found with the elbow method?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
